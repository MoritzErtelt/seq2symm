{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8d89ad-b188-4b3f-97a0-a0e1240e8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import esm\n",
    "from data_loader import TestSequencesLoader, TestFASTALoader\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda353d2-9d89-40de-90be-1a3b7e04988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n",
      "cuda is available\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from finetune import ESMFinetuner\n",
    "\n",
    "seed = 12306\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda is available')\n",
    "    \n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "# optional, if you have an A100 gpu\n",
    "#torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b759fc-ccaf-477c-88a5-191e4d132596",
   "metadata": {},
   "source": [
    "### Initialize parameters that need to be set for the model to load and predict\n",
    "##### 1. Change the \"chkpt_file\" parameter here to the full absolute path to the location where the model file is saved\n",
    "##### 2. Change the \"output_dir\" parameter to point to the full absolute path where you want the results saved. If you have an experiment specific suffix to add, modify the \"suffix\" parameter.\n",
    "##### 3. Change the batch-size, \"bs\" based on what would fit in your gpu memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fddbe07b-1d74-4413-b30f-0ee398c8243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.test_mode = True\n",
    "        self.n_classes = 20\n",
    "        self.granularity = 3\n",
    "        self.bs = 64\n",
    "        self.output_dir = \"./outputs\"\n",
    "        self.suffix = \"seq2symm\"\n",
    "        self.n_epoch = 1\n",
    "        self.num_layers_frozen = 31\n",
    "        self.weighted_sampler = False\n",
    "        self.use_soft_labels = False\n",
    "        self.chkpt_file = \"../../models/ESM2_model.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ff0d6-8c63-4ef9-bee0-38830f6269c5",
   "metadata": {},
   "source": [
    "#### Define method that aggregates predictions across batches / multiple gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86c667c-7fde-47f9-aa7f-9878c92b47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_predictions(d):\n",
    "    res_dict = dict()\n",
    "    res=[]\n",
    "    for i in range(len(d)):\n",
    "       res.append(d[i][1])\n",
    "    y_pred=np.row_stack(res)\n",
    "    print(y_pred.shape)\n",
    "    res_dict['y_pred'] = y_pred\n",
    "\n",
    "    res=[]\n",
    "    for i in range(len(d)):\n",
    "       res.append(d[i][2])\n",
    "    y_true=np.row_stack(res)\n",
    "    if y_true.dtype == np.float64:\n",
    "        # Convert to integers\n",
    "        y_true = y_true.astype(np.int64)\n",
    "    res_dict['y_true'] = y_true\n",
    "    \n",
    "    res=[]\n",
    "    for i in range(len(d)):\n",
    "       res=res+d[i][0]\n",
    "    pdbids = res\n",
    "    res_dict['pdbids'] = pdbids\n",
    "\n",
    "    print('Size of predicted logits: ',y_pred.shape,' number of proteins: ',len(pdbids))\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025c330-9f64-404b-a1cc-90dbe7119c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ea0282b-065c-419a-83f5-5380902b3e8c",
   "metadata": {},
   "source": [
    "#### Initialize the model, load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b1faa8-ad2c-4938-b9ad-a8edc01adb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune import ESMFinetuner\n",
    "\n",
    "params = Params()\n",
    "task = ESMFinetuner(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f188e5-e0f6-4847-a2a8-0dcb777276f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task.load_from_checkpoint(params.chkpt_file)\n",
    "task = task.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811bc798-2fa4-47de-9634-fcf4760a18b0",
   "metadata": {},
   "source": [
    "#### Initialize trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4d1fc3-958a-45d9-9dfa-c985cf587c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"cuda\", max_epochs=params.n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7187573-3033-45a2-b54d-a1e7e3d288bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e3168d9-2b9c-4aa4-9338-25c8df5a3bb5",
   "metadata": {},
   "source": [
    "### Usecase 1: initialize dataloader for a FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f785d49-73ec-487e-bd40-207b5d361055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set \"fasta_file\" parameter to point to absolute path of your input data\n",
    "params.fasta_file = \"all_seqs.fasta\"\n",
    "\n",
    "## Create data loader\n",
    "dataloader = TestFASTALoader(params=params, collater=task.batch_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56cb00e5-0000-42f8-8c17-272de232df3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyFileLoader Reading:  metadata.csv\n",
      "....with header: Index(['PDBID', 'SEQUENCE', 'SYMM'], dtype='object')  and length: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:07<00:00,  2.38s/it]\n",
      "(151, 20)\n",
      "Size of predicted logits:  (151, 20)  number of proteins:  151\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model=task, dataloaders=[dataloader.test_dataloader()])\n",
    "predictions = aggregate_predictions(predictions)\n",
    "\n",
    "## get probabilities if needed\n",
    "probs = torch.sigmoid(torch.tensor(predictions['y_pred']))\n",
    "predictions['probabilities'] = probs\n",
    "\n",
    "## save predictions to a pickle\n",
    "with open(format('%s/test_predictions_%s.pkl' % (params.output_dir,params.suffix)), 'wb') as fout:\n",
    "    pickle.dump(predictions, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe76f2-4637-4f76-a6ba-bb644decd45a",
   "metadata": {},
   "source": [
    "#### save predictions to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a59d1ad-208c-4bf9-80c9-ebb73d81ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up label map for 20 classes: 17 classes + 3 coarse-grained classes that indicate \n",
    "# high order C symmetry CX, high order D symmetry DX or other high order symmetry\n",
    "\n",
    "symm_to_label_map = {'C1':0,'C2':1,'C3':2,'C4':3,'C5':4,'C6':5,'C7':6,'C8':6,'C9':6,'C10':7,'C11':7,'C12':7,'C13':7,'C14':7,\n",
    "'C15':7,'C16':7,'C17':7,'D2':8,'D3':9,'D4':10,'D5':11,'D6':12,'D7':12,'D8':12,'D9':12,'D10':12,'D11':12,'D12':12,'H':13,'O':14,'T':15, 'I':16}\n",
    "symm_to_label_map['CX']=17\n",
    "symm_to_label_map['DX']=18\n",
    "symm_to_label_map['HOTI']=19\n",
    "\n",
    "label_to_symm_map = {v: k for k, v in symm_to_label_map.items()}\n",
    "label_to_symm_map[6]='C6-C9'\n",
    "label_to_symm_map[7]='C10-C17'\n",
    "label_to_symm_map[12]='D6-D12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "827f3a2c-4872-4cd8-981e-6569815f42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities for each class (note: this is multi-label classification, so the sum of all probabilities for a protein will not be equal to 1)\n",
    "probs = torch.sigmoid(torch.tensor(predictions['y_pred']))\n",
    "\n",
    "num_examples, num_classes = probs.shape\n",
    "\n",
    "positive_class_strings = ['' for _ in range(num_examples)]\n",
    "\n",
    "# Process each class independently\n",
    "for class_idx in range(num_classes):\n",
    "    positive_examples = probs[:, class_idx] >= 0.5\n",
    "    for i in np.where(positive_examples)[0]:   \n",
    "        positive_class_strings[i] += format(\" %s:%.3f\" % (label_to_symm_map[class_idx],probs[i, class_idx].numpy()))\n",
    "\n",
    "## save to a text file\n",
    "with open(format('%s/predictions_%s.txt' % (params.output_dir,params.suffix)), 'w') as fout:\n",
    "    for (protid, labels) in zip(predictions['pdbids'], positive_class_strings):\n",
    "        fout.write(f\"{protid},{labels}\\n\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572939c-0957-42cf-af03-3f3397f5259b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7156b98a-8d7f-4485-be57-631a4eeeaf92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usecase 2: Initialize dataloader for a CSV file with sequence and labels in it\n",
    "##### the CSV file needs to have at least these columns:  PDBID, SEQUENCE, SYMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f42dccd3-76ce-4449-b097-23bea8f430eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## absolute path to your CSV file\n",
    "params.meta_data_file = 'metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30c132fd-74e6-4248-96c5-0af1c10d0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = TestSequencesLoader(params=params, collater=task.batch_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd8f9c42-39cc-49c6-89d7-4ba144bb7e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyFileLoader Reading:  metadata.csv\n",
      "....with header: Index(['PDBID', 'SEQUENCE', 'SYMM'], dtype='object')  and length: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:07<00:00,  2.38s/it]\n",
      "(151, 20)\n",
      "Size of predicted logits:  (151, 20)  number of proteins:  151\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model=task, dataloaders=[dataloader.test_dataloader()])\n",
    "predictions = aggregate_predictions(predictions)\n",
    "\n",
    "## get probabilities if needed\n",
    "probs = torch.sigmoid(torch.tensor(predictions['y_pred']))\n",
    "predictions['probabilities'] = probs\n",
    "\n",
    "with open(format('%s/test_predictions_%s.pkl' % (params.output_dir,params.suffix)), 'wb') as fout:\n",
    "    pickle.dump(predictions, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c1ba4ee-73bd-4490-91d3-fca4d4bc09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['y_pred', 'y_true', 'pdbids', 'probabilities'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4796983-20ed-41f5-94fa-617b48f0d2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RF2lightning",
   "language": "python",
   "name": "rf2lightning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
